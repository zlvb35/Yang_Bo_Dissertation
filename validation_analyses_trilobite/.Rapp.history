install.packages("palec", repos = c(getOption("repos"), "https://ms609.github.io/packages"))
source("https://raw.githubusercontent.com/balsedie/trilomorph/main/TriloMorph-funs.R")
#access TriloMorph metadata#
trilomorph_metadata <- yaml_read(file="https://raw.githubusercontent.com/balsedie/trilomorph/main/trilomorph.yaml")#
#
#keep only information on specimens that have cephalon information. #
#In case you want to analyse pygidia, you just need to change cephalon for pygidium in the line below#
trilomorph_metadata <- trilomorph_metadata[which(trilomorph_metadata$morphology.cephalon),]
#access TriloMorph metadata#
trilomorph_metadata <- yaml_read(file="https://raw.githubusercontent.com/balsedie/trilomorph/main/trilomorph.yaml")
#keep only information on specimens that have cephalon information. #
#In case you want to analyse pygidia, you just need to change cephalon for pygidium in the line below#
trilomorph_metadata <- trilomorph_metadata[which(trilomorph_metadata$morphology.cephalon),]
#define the vector of specimens' IDs to read the shape files#
fids <- trilomorph_metadata$ID#
#
#set the path to the unzipped folder with the shape files#
dirlm <- "~path/to_the/downloaded/folder" #
#
#define the desired landmark configuration. It is a list stating dimensions, curves, number of semilandmarks, #
#and maximum curves in in the dataset: in this case 2 dimensions, landmarks 1 to 16, 4 curves (out of 4 possible), #
#12, 20, 20 and 20 semilandmarks for each curve respectively, and the curves in the trilomorph template.#
nlms <-  list(dim = 2, #dimensions (2d)#
         lm = c(1:16), #vector of desired fixed landmark configuration#
         cv = c("glabella","suture","anterior","posterior"), #names or numbers of desired curves#
         cvs.lm = c(12, 20, 20, 20), #number of subsampled semilandmarks in each curve#
         curves.id = c("glabella","suture","anterior","posterior") #names of maximum number of curves in the dataset#
         )#
#
#note to change this configuration if analysing pygidia. Trilomorph template[^6] defines up to 3 pygidial curves.#
#nlms <- list(dim = 2, #dimensions (2d)#
         lm = c(1:7), #vector of desired configuration#
         cv = c("axis","border","margin"), #names or numbers of desired curves#
         cvs.lm = c(x,x,x), #number of subsampled semilandmarks in each curve#
         curves.id = c("axis","border","margin") #names of maximum number of curves in the dataset#
         )#
#
#read the shape files. Note that sufix = "_C" is for cephala, change it to "_P" if analysing pygidia.#
lmks <- shapRead(fids, sufix = "_C", subdir = dirlm)#
#
#remove specimens that don't fit the desired landmark configuration.#
ldks <- shapFix(lmks, nlms)
source("https://raw.githubusercontent.com/balsedie/trilomorph/main/TriloMorph-funs.R")
#access TriloMorph metadata#
trilomorph_metadata <- yaml_read(file="https://raw.githubusercontent.com/balsedie/trilomorph/main/trilomorph.yaml")#
#
#keep only information on specimens that have cephalon information. #
#In case you want to analyse pygidia, you just need to change cephalon for pygidium in the line below#
trilomorph_metadata <- trilomorph_metadata[which(trilomorph_metadata$morphology.cephalon),]
#define the vector of specimens' IDs to read the shape files#
fids <- trilomorph_metadata$ID#
#
#set the path to the unzipped folder with the shape files#
dirlm <- "~path/to_the/downloaded/folder" #
#
#define the desired landmark configuration. It is a list stating dimensions, curves, number of semilandmarks, #
#and maximum curves in in the dataset: in this case 2 dimensions, landmarks 1 to 16, 4 curves (out of 4 possible), #
#12, 20, 20 and 20 semilandmarks for each curve respectively, and the curves in the trilomorph template.#
nlms <-  list(dim = 2, #dimensions (2d)#
         lm = c(1:16), #vector of desired fixed landmark configuration#
         cv = c("glabella","suture","anterior","posterior"), #names or numbers of desired curves#
         cvs.lm = c(12, 20, 20, 20), #number of subsampled semilandmarks in each curve#
         curves.id = c("glabella","suture","anterior","posterior") #names of maximum number of curves in the dataset#
         )#
#
#note to change this configuration if analysing pygidia. Trilomorph template[^6] defines up to 3 pygidial curves.#
#nlms <- list(dim = 2, #dimensions (2d)#
         lm = c(1:7), #vector of desired configuration#
         cv = c("axis","border","margin"), #names or numbers of desired curves#
         cvs.lm = c(x,x,x), #number of subsampled semilandmarks in each curve#
         curves.id = c("axis","border","margin") #names of maximum number of curves in the dataset#
         )#
#
#read the shape files. Note that sufix = "_C" is for cephala, change it to "_P" if analysing pygidia.#
lmks <- shapRead(fids, sufix = "_C", subdir = dirlm)#
#
#remove specimens that don't fit the desired landmark configuration.#
ldks <- shapFix(lmks, nlms)
#first load the geomorph package#
library(geomorph)#
#
#Superimpose by GPA.#
gpan <- geomorph::gpagen(ldks, Proj = TRUE, PrinAxes = FALSE)#
#
# Construct the morphospace of selected configurations.#
# This morphological space is reconstructed by means of a principal components analysis (PCA).#
pcan <- geomorph::gm.prcomp(gpan$coords)#
#
#you can now plot the morphospace very easily#
geomorph:::plot.gm.prcomp(pcan, main = "PCA-based morphospace", pch = 21, bg = "lightgray", cex = 1.5)#
mtext(paste0("n = ", nrow(pcan$x)), side = 3, adj = 1, font = 3)
library(StereoMorph)
setwd('/Users/Remi/Desktop/Edodiscida_Project')
setwd('/Users/Desktop/Eodiscida_Project')
source('~/Downloads/TriloMorph-funs.R', chdir = TRUE)
shapFix
source('~/Downloads/TriloMorph-funs.R', chdir = TRUE)
stereo-file <- "/Users/remi/Desktop/Eodiscida_Project/Shapes/Shizhudiscus_longquanensis.txt"
setwd('/Users/remi/Desktop/Eodiscida_Project/Shapes/Shizhudiscus_longquanensis.txt')
source('~/Downloads/TriloMorph-funs.R', chdir = TRUE)
setwd('/Users/remi/Desktop/Eodiscida_Project_Shapes/Shizhudiscus_longquanensis.txt')
file_path <- "/Users/remi/Desktop/Eodiscida_Project_Shapes/Shizhudiscus_longquanensis.txt"
landmark_data <- shapRead(file_path)
print(landmark_data)
file_content <- readLines(file_path)
file_path <- "/Users/remi/Desktop/Shizhudiscus_longquanensis_cleaned.txt"
landmark_data <- shapRead(file_path)
print(landmark_data)
library(geomorph)
data("scallopPLY")
my.ply <- scallopPLY$ply
fixed.lms1 <- digit.fixed(spec = my.ply, fixed=5)
my.ply.2 <- scallopPLY$ply
fixed.lms <- digit.fixed(my.ply.2, 5)
n#
#
> surf.pts2 <- digitsurface(spec = my.ply.2, fixed = fixed.lms2)
n
n#
>.
n#
>.#
>n
> data("scallopPLY")#
> my.ply <- scallopPLY$ply#
> fixed.lms1 <- digit.fixed(spec = my.ply, fixed=5)
data("scallopPLY")#
my.ply <- scallopPLY$ply#
fixed.lms1 <- digit.fixed(spec = my.ply, fixed=5)
my.ply.2 <- scallopPLY$ply#
fixed.lms <- digit.fixed(my.ply.2, 5)
source('~/Downloads/TriloMorph_Functions.r', chdir = TRUE)
setwd('/Users/remi/Desktop/Redlichiia_Project/Shapes')
getwd()
setwd('/Users/remi/Desktop/Redlichiia_Project/Shapes')
setwd('/Users/remi')
setwd('/Desktop/Redlichiida_Project/Shapes')
# ----------------------------------------#
# Perform GPA Analysis#
# ----------------------------------------#
# Perform Generalized Procrustes Analysis#
gpan <- geomorph::gpagen(processed_specimens, #
                        Proj = TRUE,      # Project onto tangent space#
                        PrinAxes = FALSE) # Don't align by principal axes#
#
# Calculate mean shape and Procrustes distances#
mean_shape <- mshape(gpan$coords)#
Pd <- c()#
for(i in 1:dim(gpan$coords)[3]) {#
    Pd[i] <- sqrt(sum((gpan$coords[,,i] - mean_shape)^2))#
}#
#
# Calculate statistics for Procrustes distances#
mean_pd <- mean(Pd)#
sd_pd <- sd(Pd)#
upper_threshold <- mean_pd + 2*sd_pd#
#
# ----------------------------------------#
# Create Visualization (Two Plots Side by Side)#
# ----------------------------------------#
# Create new plotting window#
dev.new(width = 12, height = 6)#
par(mfrow = c(1,2))#
#
# ----------------------------------------#
# Plot 1: Superimposition Plot#
# ----------------------------------------#
# Set up empty plot#
plot(NA, NA, #
     xlim = range(gpan$coords[,1,]), #
     ylim = range(gpan$coords[,2,]),#
     xlab = "X coordinate (Procrustes aligned)",#
     ylab = "Y coordinate (Procrustes aligned)",#
     main = "Procrustes Superimposition of Trilobite Cephalon")#
#
# Plot individual specimens#
for(i in 1:dim(gpan$coords)[3]) {#
    points(gpan$coords[,,i], #
           pch = 20,       #
           col = "gray50", #
           cex = 0.3)      #
}#
#
# Plot consensus shape#
points(mean_shape, #
       pch = 16,        #
       cex = 1.2,       #
       col = "black")   #
#
# Add sample size#
mtext(paste0("n = ", dim(gpan$coords)[3]), #
      side = 3, #
      adj = 1, #
      font = 3)#
#
# Add legend at bottom left#
legend("bottomleft", #
       legend = c("Consensus shape", "Individual specimens"),#
       col = c("black", "gray50"), #
       pch = c(16, 20),#
       pt.cex = c(1.2, 0.3),#
       cex = 0.8,#
       bty = "n",#
       inset = 0.02)#
#
# ----------------------------------------#
# Plot 2: Procrustes Distances Histogram#
# ----------------------------------------#
 Create histogram#
hist(Pd, #
     main = "Procrustes Distances from Consensus",#
     xlab = "Procrustes Distance",#
     ylab = "Frequency",#
     ylim = c(0, 20),#
     breaks = sqrt(dim(gpan$coords)[3]),#
     col = "lightblue",#
     border = "white")#
#
# Add vertical lines to maximum height#
segments(x0 = mean_pd, y0 = 0, x1 = mean_pd, y1 = 20, col = "red", lwd = 2)#
segments(x0 = upper_threshold, y0 = 0, x1 = upper_threshold, y1 = 20, #
         col = "red", lty = 2, lwd = 2)#
#
# Add text annotations - all at y=20#
# Mean label on the left side of its line#
text(mean_pd, 20, paste("Mean =", round(mean_pd, 3)), #
     pos = 2,  # Left side#
     col = "red", #
     cex = 0.8)#
#
# Outlier threshold label on the right side of its line#
text(upper_threshold, 20, paste("Outlier threshold =", round(upper_threshold, 3)), #
     pos = 4,  # Right side#
     col = "red", #
     cex = 0.8)#
#
# SD between mean and threshold lines#
text((mean_pd + upper_threshold)/2, 20,  # Position between the two lines#
     paste("SD =", round(sd_pd, 3)),#
     col = "black", #
     cex = 0.8)#
#
# Return to default plotting parameters#
par(mfrow = c(1,1))#
#
# ----------------------------------------#
# Print Analysis Results#
# ----------------------------------------#
cat("\nGPA Analysis Summary:\n")#
cat("----------------------------------------\n")#
cat("Number of specimens:", dim(gpan$coords)[3], "\n")#
cat("Procrustes Sum of Squares:", gpan$procD, "\n")#
cat("Tangent Sum of Squares:", gpan$tangentD, "\n")#
#
cat("\nProcrustes Distances from Consensus:\n")#
cat("Mean:", round(mean_pd, 4), "\n")#
cat("SD:", round(sd_pd, 4), "\n")#
cat("Range:", round(range(Pd), 4), "\n")#
#
# Identify potential outliers#
potential_outliers <- which(Pd > upper_threshold)#
if(length(potential_outliers) > 0) {#
    cat("\nPotential outliers (>2SD from mean):\n")#
    cat("Specimen IDs:\n")#
    print(dimnames(gpan$coords)[[3]][potential_outliers])#
    cat("\nTheir Procrustes distances:\n")#
    print(round(Pd[potential_outliers], 4))#
}#
#
# Save results#
save(gpan, Pd, mean_shape, file = "gpa_analysis_results.RData")
# -------------------------------------------------------------------------------------------------#
# Performing GPA Analysis#
# -------------------------------------------------------------------------------------------------#
#
# ----------------------------------------#
# Load saved processed landmarks (if needed)#
# ----------------------------------------#
if(!exists("processed_specimens")) {#
    load("processed_landmarks.RData")#
}
source('~/Downloads/英文版Workflow.r', chdir = TRUE)
# Procrustes Sum of Squares#
procD <- sum((gpan$coords - array(gpan$consensus, dim=dim(gpan$coords)))^2)
# Tangent Sum of Squares (考虑投影效应)#
# 使用geomorph包的内部函数进行计算#
tangentD <- procD * cos(sqrt(procD)/2)^2
# Print analysis results#
cat("\nGPA Analysis Summary:\n")#
cat("----------------------------------------\n")#
cat("Number of specimens:", dim(gpan$coords)[3], "\n")#
cat("Procrustes Sum of Squares:", round(procD, 4), "\n")#
cat("Tangent Sum of Squares:", round(tangentD, 4), "\n")#
#
cat("\nProcrustes Distances from Consensus:\n")#
cat("Mean:", round(mean_pd, 4), "\n")#
cat("SD:", round(sd_pd, 4), "\n")#
cat("Range:", round(range(Pd), 4), "\n")
# 正确计算 Procrustes Sum of Squares#
procD <- sum(Pd^2)  # 使用已经计算好的Procrustes距离的平方和#
#
# 计算 Tangent Sum of Squares#
tangentD <- procD * cos(sqrt(procD)/2)^2#
#
cat("Procrustes Sum of Squares:", round(procD, 4), "\n")#
cat("Tangent Sum of Squares:", round(tangentD, 4), "\n")
# -------------------------------------------------------------------------------------------------#
# PCA Morphospace with Proper Deformation Grids#
# -------------------------------------------------------------------------------------------------#
#
# Load required packages#
library(geomorph)#
library(Morpho)  # For proper deformation grid generation
# ----------------------------------------#
# Setup for visualization#
# ----------------------------------------#
# Define specific positions along PC1 where we want grids#
grid_positions <- c(-0.4, -0.2, 0, 0.2, 0.4)#
n_grids <- length(grid_positions)#
#
# Generate predicted shapes for each position#
ref_shape <- mshape(gpan$coords)#
pred_shapes <- list()#
#
# Generate shapes for each position#
for(i in 1:n_grids) {#
    pred_shapes[[i]] <- ref_shape + pcan$rotation[,1] * grid_positions[i] * pcan$sdev[1]#
}
# ----------------------------------------#
# Create visualization#
# ----------------------------------------#
# Set up the plotting device#
dev.new(width = 12, height = 10)#
#
# Create layout matrix#
# Top part for PCA plot, bottom part for deformation grids#
layout_matrix <- matrix(c(rep(1,3), rep(2:6, each=2)), ncol=5, byrow=TRUE)#
layout(layout_matrix, heights = c(3,2))
# ----------------------------------------#
# Plot 1: PCA Morphospace (top)#
# ----------------------------------------#
par(mar = c(4,4,1,1))#
#
# Draw main PCA plot#
plot(pcan$x[,1], pcan$x[,2],#
     xlim = c(-0.4, 0.4),  # Set correct x-axis range#
     ylim = range(pcan$x[,2]),#
     xlab = paste0("PC1 (", round(prop_var[1]*100, 1), "%)"),#
     ylab = paste0("PC2 (", round(prop_var[2]*100, 1), "%)"),#
     type = "n",#
     asp = 1)
install.packages("geomorph")
source('~/Downloads/validation_analyses.r', chdir = TRUE)
# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
# Validation Analyses Of Substitution Loci (Landmark 11 + Landmark 12)#
# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
load("gpa_analysis_results.RData")  # All specimens#
load("gpa_analysis_results_no_olenellina.RData")  # Non-Olenellina specimens#
#
# -----------------------------------------------------#
# Step 1: Analysis Function Definition#
# -----------------------------------------------------#
analyze_all_landmarks <- function(gpa_data, group_name = "") {#
    # Extract all fixed landmarks (1-16)#
    n_landmarks <- 16#
    landmark_coords <- gpa_data$coords[1:n_landmarks,,]#
    n_specimens <- dim(landmark_coords)[3]#
    # Calculate mean position (consensus) for each landmark#
    landmark_consensus <- apply(landmark_coords, c(1,2), mean)#
    # Initialise array for storing individual landmark distances#
    landmark_proc_dist <- array(0, dim = c(n_specimens, n_landmarks))#
    # Calculate procrustes distances for each landmark#
    for(i in 1:n_specimens) {#
        for(j in 1:n_landmarks) {#
            landmark_proc_dist[i,j] <- sqrt(sum((landmark_coords[j,,i] - landmark_consensus[j,])^2))#
        }#
    }#
#
    # Calculate summary statistics for each landmark#
    landmark_stats <- list()#
    for(i in 1:n_landmarks) {#
        distances <- landmark_proc_dist[,i]#
        landmark_stats[[i]] <- list(#
            landmark = paste0("LM", i),#
            mean = mean(distances),#
            sd = sd(distances),#
            cv = sd(distances)/mean(distances) * 100,#
            min = min(distances),#
            max = max(distances)#
        )#
    }#
    results <- list(#
        group = group_name,#
        n_specimens = n_specimens,#
        landmark_stats = landmark_stats#
    )#
    return(results)#
}#
#
# -----------------------------------------------------#
# Step 2: Generate Report Function#
# -----------------------------------------------------#
generate_landmark_report <- function(results_all, results_no_olenellina) {#
    cat("\n=== Complete Landmark Position Analysis Report ===\n")#
    cat("\n1. Sample Sizes:\n")#
    cat("All Specimens:", results_all$n_specimens, "\n")#
    cat("Non-Olenellina:", results_no_olenellina$n_specimens, "\n")#
    # Create comprehensive comparison dataframe#
    comparison_df <- data.frame(#
        Landmark = character(),#
        Mean_All = numeric(),#
        Mean_NonOlen = numeric(),#
        SD_All = numeric(),#
        SD_NonOlen = numeric(),#
        CV_All = numeric(),#
        CV_NonOlen = numeric(),#
        CV_Difference = numeric(),#
        stringsAsFactors = FALSE#
    )#
    for(i in 1:16) {#
        stats_all <- results_all$landmark_stats[[i]]#
        stats_no_olen <- results_no_olenellina$landmark_stats[[i]]#
        comparison_df[i,] <- c(#
            paste0("LM", i),#
            stats_all$mean,#
            stats_no_olen$mean,#
            stats_all$sd,#
            stats_no_olen$sd,#
            stats_all$cv,#
            stats_no_olen$cv,#
            stats_all$cv - stats_no_olen$cv#
        )#
    }#
    # Convert numeric columns#
    numeric_cols <- 2:ncol(comparison_df)#
    comparison_df[,numeric_cols] <- apply(comparison_df[,numeric_cols], 2, as.numeric)#
    cat("\n2. Individual Landmark Analysis:\n")#
    print(format(comparison_df, digits = 4))#
    # Calculate statistics for non-substituted landmarks#
    non_subst_indices <- c(1:10, 13:16)#
    cv_non_subst_all <- comparison_df$CV_All[non_subst_indices]#
    cv_non_subst_no_olen <- comparison_df$CV_NonOlen[non_subst_indices]#
    cat("\n3. Analysis Summary:\n")#
#
    # Performance of substituted landmarks#
    cat("\na) Performance of Substituted Landmarks:\n")#
    cat("LM11 CV: All =", round(comparison_df$CV_All[11], 2), #
        "%, Non-Olenellina =", round(comparison_df$CV_NonOlen[11], 2), "%\n")#
    cat("LM12 CV: All =", round(comparison_df$CV_All[12], 2), #
        "%, Non-Olenellina =", round(comparison_df$CV_NonOlen[12], 2), "%\n")#
    # Overall landmark variation#
    cat("\nb) Overall Landmark Variation:\n")#
    cat("Non-substituted landmarks CV range:\n")#
    cat("All Specimens:", round(min(cv_non_subst_all), 2), "% to", #
        round(max(cv_non_subst_all), 2), "%\n")#
    cat("Non-Olenellina:", round(min(cv_non_subst_no_olen), 2), "% to", #
        round(max(cv_non_subst_no_olen), 2), "%\n")#
    # Mean CV for context#
    cat("\nc) Mean CV for context:\n")#
    cat("Mean CV (non-substituted landmarks) - All Specimens:", #
        round(mean(cv_non_subst_all), 2), "%\n")#
    cat("Mean CV (non-substituted landmarks) - Non-Olenellina:", #
        round(mean(cv_non_subst_no_olen), 2), "%\n")#
    # Save results#
    write.csv(comparison_df, "landmark_complete_analysis.xlsx", row.names = FALSE)#
}
# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
# STEP 0: Set Up R Environemnt #
# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
# -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
#
# Clean environment and set up workspace#
rm(list=ls(all=TRUE))#
graphics.off()
# ----------------------------------------#
# Process file names#
# ----------------------------------------#
# Get file list#
files <- list.files("xml_output_dataset", pattern = "\\.txt$", full.names = TRUE)#
cat("Found", length(files), "text files\n")#
#
# Process file names (Remove extra .txt extensions)#
file_names <- basename(files)#
clean_names <- gsub("\\.txt\\.txt$", ".txt", file_names)#
clean_names <- gsub("\\.txt$", "", clean_names)
>citation("StereoMorph")
citation("StereoMorph")
# ---------------------------------------------#
# 2. Data Preparation#
# ---------------------------------------------#
# Load specimen-order mapping information#
load("specimen_order_mapping.RData")  # loads specimen_orders object#
#
# Load complete dataset (81 specimens)#
load("gpa_analysis_results.RData")  # loads as gpa_results#
gpan_full <- gpa_results#
#
# Load dataset without olenellina (69 specimens)#
load("gpa_analysis_results_no_olenellina.RData")  # loads as gpa_no_olenellina#
gpan_nonolen <- gpa_no_olenellina#
#
# Define olenellina specimens#
olenellina_species <- c(#
    "Choubertella_spinosa",#
    "Daguinaspis_ambroggii",#
    "Elliptocephala_asaphoides",#
    "Fallotaspis_bondoni",#
    "Holmia_kjerulfi",#
    "Judomia_tera",#
    "Montezumaspis_parallela",#
    "Nephrolenellus_geniculatus",#
    "Nevadia_weeksi",#
    "Olenellus_gilberti",#
    "Peachella_iddingsi",#
    "Wanneria_walcottana"#
)#
#
# ---------------------------------------------#
# 3. PCA Analysis#
# ---------------------------------------------#
# Perform PCA on complete dataset#
pca_full <- gm.prcomp(gpan_full$coords)#
#
# Extract indices for non-olenellina specimens#
non_olen_indices <- !sapply(dimnames(gpan_full$coords)[[3]], function(x) {#
    any(sapply(olenellina_species, function(y) grepl(y, x, ignore.case = TRUE)))#
})#
#
# Extract PCA scores for non-olenellina specimens from complete dataset#
pca_scores_full_nonolen <- pca_full$x[non_olen_indices, ]#
#
# Perform PCA on dataset without olenellina#
pca_nonolen <- gm.prcomp(gpan_nonolen$coords)#
#
# ---------------------------------------------#
# 4. Visualisation#
# ---------------------------------------------#
# Calculate explained variance#
var_full <- (pca_full$sdev^2)/sum(pca_full$sdev^2) * 100#
var_nonolen <- (pca_nonolen$sdev^2)/sum(pca_nonolen$sdev^2) * 100#
#
# Create a vector for olenellina indices in the full dataset#
olenellina_indices <- sapply(dimnames(gpan_full$coords)[[3]], function(x) {#
    any(sapply(olenellina_species, function(y) grepl(y, x, ignore.case = TRUE)))#
})#
#
# Set up plotting window with appropriate margins#
dev.new(width = 8, height = 6)#
par(mar = c(5, 5, 4, 2))  # Bottom, left, top, right margins#
#
# Create main plot area for complete dataset#
plot(NA, NA,#
     xlim = range(pca_full$x[,1]),#
     ylim = range(pca_full$x[,2]),#
     xlab = paste0("PC1 (", round(var_full[1], 1), "%)"),#
     ylab = paste0("PC2 (", round(var_full[2], 1), "%)"),#
     main = "PCA Comparison",#
     asp = 1)#
#
# Add zero lines#
abline(h = 0, v = 0, lty = 2, col = "gray")#
#
# Add non-Olenellina points from complete dataset (black solid circles)#
points(pca_full$x[!olenellina_indices,1], #
       pca_full$x[!olenellina_indices,2],#
       pch = 19,  # Solid circle#
       col = "black",#
       cex = 1.2)#
#
# Add Olenellina points from complete dataset (red solid circles)#
points(pca_full$x[olenellina_indices,1], #
       pca_full$x[olenellina_indices,2],#
       pch = 4,  # Solid circle#
       col = "red",#
       cex = 1.2)#
#
# Add non-Olenellina subset points (gray open circles)#
points(pca_nonolen$x[,1], #
       pca_nonolen$x[,2],#
       pch = 1,   # Open circle#
       col = "gray50",#
       cex = 1.2)#
#
# Add legend on the right side#
legend("topright", #
       legend = c("Complete dataset (Non-Olenellina)", #
                 "Complete dataset (Olenellina)",#
                 "Non-Olenellina subset"),#
       col = c("black", "red", "gray50"),#
       pch = c(19, 4, 1),#
       cex = 0.7,#
       bty = "n")#
#
# Add sample size information at the top#
mtext("Complete dataset: n = 81", #
      side = 3, line = 0, adj = 0, font = 3)#
mtext("Non-Olenellina subset: n = 69", #
      side = 3, line = 1, adj = 0, font = 3, col = "gray50")#
#
# Add Non-Olenellina PC variance information (gray text)#
mtext(paste0("PC1 (", round(var_nonolen[1], 1), "%)"), #
      side = 1, line = 3, col = "gray50", adj = 0.75)  # Near right end of x-axis#
#
mtext(paste0("PC2 (", round(var_nonolen[2], 1), "%)"), #
      side = 2, line = 3, col = "gray50", adj = 0.9)  # Near top of y-axis#
#
# Save the plot#
dev.copy2pdf(file = "combined_pca_comparison.pdf")
# ---------------------------------------------#
# 2. Data Preparation#
# ---------------------------------------------#
# Load specimen-order mapping information#
load("specimen_order_mapping.RData")  # loads specimen_orders object#
#
# Load complete dataset (81 specimens)#
load("gpa_analysis_results.RData")  # loads as gpa_results#
gpan_full <- gpa_results#
#
# Load dataset without olenellina (69 specimens)#
load("gpa_analysis_results_no_olenellina.RData")  # loads as gpa_no_olenellina#
gpan_nonolen <- gpa_no_olenellina#
#
# Define olenellina specimens#
olenellina_species <- c(#
    "Choubertella_spinosa",#
    "Daguinaspis_ambroggii",#
    "Elliptocephala_asaphoides",#
    "Fallotaspis_bondoni",#
    "Holmia_kjerulfi",#
    "Judomia_tera",#
    "Montezumaspis_parallela",#
    "Nephrolenellus_geniculatus",#
    "Nevadia_weeksi",#
    "Olenellus_gilberti",#
    "Peachella_iddingsi",#
    "Wanneria_walcottana"#
)
# ---------------------------------------------#
# 1. Set up Environment#
# ---------------------------------------------#
# Set working directory#
setwd("~/Desktop/validation_analyses_trilobite")#
#
# Load required packages#
library(geomorph)#
library(vegan)#
library(ggplot2)
# ---------------------------------------------#
# 2. Data Preparation#
# ---------------------------------------------#
# Load specimen-order mapping information#
load("specimen_order_mapping.RData")  # loads specimen_orders object#
#
# Load complete dataset (81 specimens)#
load("gpa_analysis_results.RData")  # loads as gpa_results#
gpan_full <- gpa_results#
#
# Load dataset without olenellina (69 specimens)#
load("gpa_analysis_results_no_olenellina.RData")  # loads as gpa_no_olenellina#
gpan_nonolen <- gpa_no_olenellina#
#
# Define olenellina specimens#
olenellina_species <- c(#
    "Choubertella_spinosa",#
    "Daguinaspis_ambroggii",#
    "Elliptocephala_asaphoides",#
    "Fallotaspis_bondoni",#
    "Holmia_kjerulfi",#
    "Judomia_tera",#
    "Montezumaspis_parallela",#
    "Nephrolenellus_geniculatus",#
    "Nevadia_weeksi",#
    "Olenellus_gilberti",#
    "Peachella_iddingsi",#
    "Wanneria_walcottana"#
)
# ---------------------------------------------#
# 3. PCA Analysis#
# ---------------------------------------------#
# Perform PCA on complete dataset#
pca_full <- gm.prcomp(gpan_full$coords)#
#
# Extract indices for non-olenellina specimens#
non_olen_indices <- !sapply(dimnames(gpan_full$coords)[[3]], function(x) {#
    any(sapply(olenellina_species, function(y) grepl(y, x, ignore.case = TRUE)))#
})#
#
# Extract PCA scores for non-olenellina specimens from complete dataset#
pca_scores_full_nonolen <- pca_full$x[non_olen_indices, ]#
#
# Perform PCA on dataset without olenellina#
pca_nonolen <- gm.prcomp(gpan_nonolen$coords)#
#
# ---------------------------------------------
# 4. Visualisation#
# ---------------------------------------------#
# Calculate explained variance#
var_full <- (pca_full$sdev^2)/sum(pca_full$sdev^2) * 100#
var_nonolen <- (pca_nonolen$sdev^2)/sum(pca_nonolen$sdev^2) * 100#
#
# Create a vector for olenellina indices in the full dataset#
olenellina_indices <- sapply(dimnames(gpan_full$coords)[[3]], function(x) {#
    any(sapply(olenellina_species, function(y) grepl(y, x, ignore.case = TRUE)))#
})#
#
# Set up plotting window with appropriate margins#
dev.new(width = 8, height = 6)#
par(mar = c(5, 5, 4, 2))  # Bottom, left, top, right margins#
#
# Create main plot area for complete dataset#
plot(NA, NA,#
     xlim = range(pca_full$x[,1]),#
     ylim = range(pca_full$x[,2]),#
     xlab = paste0("PC1 (", round(var_full[1], 1), "%)"),#
     ylab = paste0("PC2 (", round(var_full[2], 1), "%)"),#
     main = "PCA Comparison",#
     asp = 1)#
#
# Add zero lines#
abline(h = 0, v = 0, lty = 2, col = "gray")#
#
# Add non-Olenellina points from complete dataset (black solid circles)#
points(pca_full$x[!olenellina_indices,1], #
       pca_full$x[!olenellina_indices,2],#
       pch = 19,  # Solid circle#
       col = "black",#
       cex = 1.2)#
#
# Add Olenellina points from complete dataset (red solid circles)#
points(pca_full$x[olenellina_indices,1], #
       pca_full$x[olenellina_indices,2],#
       pch = 4,  # Solid circle#
       col = "red",#
       cex = 1.2)#
#
# Add non-Olenellina subset points (gray open circles)#
points(pca_nonolen$x[,1], #
       pca_nonolen$x[,2],#
       pch = 1,   # Open circle#
       col = "gray50",#
       cex = 1.2)#
#
# Add legend on the right side#
legend("topright", #
       legend = c("Complete dataset (Non-Olenellina)", #
                 "Complete dataset (Olenellina)",#
                 "Non-Olenellina subset"),#
       col = c("black", "red", "gray50"),#
       pch = c(19, 4, 1),#
       cex = 0.7,#
       bty = "n")#
#
# Add sample size information at the top#
mtext("Complete dataset: n = 81", #
      side = 3, line = 0, adj = 0, font = 3)#
mtext("Non-Olenellina subset: n = 69", #
      side = 3, line = 1, adj = 0, font = 3, col = "gray50")#
#
# Add Non-Olenellina PC variance information (gray text)#
mtext(paste0("PC1 (", round(var_nonolen[1], 1), "%)"), #
      side = 1, line = 3, col = "gray50", adj = 0.75)  # Near right end of x-axis#
#
mtext(paste0("PC2 (", round(var_nonolen[2], 1), "%)"), #
      side = 2, line = 3, col = "gray50", adj = 0.9)  # Near top of y-axis#
#
# Save the plot#
dev.copy2pdf(file = "combined_pca_comparison.pdf")
